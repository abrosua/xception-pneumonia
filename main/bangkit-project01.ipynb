{"cells":[{"metadata":{"_uuid":"d55fffdc-5660-46c1-972f-f5545849e01a","_cell_guid":"58901748-6ce4-4b74-a91b-c8c71d561f38","trusted":true},"cell_type":"markdown","source":"# Importing Modules"},{"metadata":{"_uuid":"3640be3b-73e9-4800-bfd9-546c40ddb803","_cell_guid":"8db34ea2-0132-4949-ba57-6b0084130df0","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport os\nimport glob\nimport shutil\nimport random\n\nimport cv2\nimport tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\n\ncolor = sns.color_palette()\n%matplotlib inline\nseed_number = 24\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nroot = \"../input\"\nprint(f\"Main directories\\t: {os.listdir(root)}\")\ninput_dir = os.path.join(root, \"chest-xray-pneumonia\", \"chest_xray\")\nprint(f\"Dataset sub-directories\\t: {os.listdir(input_dir)}\")\nprint(f\"Train set directory\\t: {os.listdir(os.path.join(input_dir, 'train'))}\")\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69183057-e823-47aa-9d98-b757b609290e","_cell_guid":"441b1991-a5fb-4994-a691-384c6544d135","trusted":true},"cell_type":"code","source":"# Import packages for data handling\nimport h5py\nfrom PIL import Image\nfrom skimage.io import imread\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom mlxtend.plotting import plot_confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71903b9b-5ab8-434e-8f13-5c2a25d37747","_cell_guid":"f17da0bf-ec46-4a74-bd7b-7de26f036217","trusted":true},"cell_type":"code","source":"# Import deep learning package (tensorflow)\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.applications import vgg16, xception\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52190562-3370-4622-ac77-e5142f7578df","_cell_guid":"63a3d04e-40be-463f-a8cf-7cbea078cb57","trusted":true},"cell_type":"code","source":"# Set seed nunmber to all packages\nrandom.seed(seed_number)\nnp.random.seed(seed_number)\ntf.random.set_seed(seed_number)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"755eda46-8536-43a2-a868-c023b099a9b4","_cell_guid":"55b1ee70-1394-4afc-9952-894ca89cd311","trusted":true},"cell_type":"markdown","source":"# Observing the Dataset\nGrasping some of the dataset information"},{"metadata":{"_uuid":"b0c33dc0-156d-41ec-807d-e8fe5ab869ba","_cell_guid":"3a33ed04-c66d-42aa-a7f6-dcc9681351b9","trusted":true},"cell_type":"code","source":"# Create train, val and test directories\ntrain_dir = os.path.join(input_dir, 'train')\nval_dir = os.path.join(input_dir, 'val')\ntest_dir = os.path.join(input_dir, 'test')\n\ndir_dict = {'train': train_dir, 'val': val_dir, 'test': test_dir}\nlabel_name = os.listdir(os.path.join(input_dir, 'train'))\ncase_count, img_disp, set_length  = {}, {}, {}\n\nfor key, val in dir_dict.items():\n    case_count[key] = {}\n    img_disp[key] = {}\n    set_count = 0\n    \n    for label in label_name:\n        label_list = list(glob.glob(os.path.join(val, label, \"*.jpeg\")))\n        case_count[key][label] = len(label_list)\n        set_count += len(label_list)\n        \n        select_img_id = random.randint(1, len(label_list)-1)\n        img_disp[key][label] = label_list[select_img_id]\n        \n    set_length[key] = set_count\n\ncase_count_df = pd.DataFrame(case_count)\nimg_disp_df = pd.DataFrame(img_disp)\nprint(f\"Dataset summary:\\n\\n{case_count_df}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d646c129-72e9-44d5-bc01-c72675137986","_cell_guid":"d6dde8c1-a9c1-470a-9fc8-a7fafe05e10b","trusted":true},"cell_type":"code","source":"# Visualizing some of the data set\nnum_classes = len(label_name)\nf, ax = plt.subplots(num_classes, 3, figsize=(30, 18))\n\nfor k in range(num_classes*3):\n    j, i = k//3, k%3  # Image indexing\n    \n    img = imread(img_disp_df.iloc[j, i])\n    ax[j, i].imshow(img, cmap='gray')\n    ax[j, i].set_title(f\"{img_disp_df.columns[i].upper()}: {img_disp_df.index[j].capitalize()}\", fontsize=32)\n    ax[j, i].axis('off')\n    ax[j, i].set_aspect('auto')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dae1f517-7c20-4107-ac7b-9449e49e93ed","_cell_guid":"eacdcd93-902a-4dda-b91b-4dcf7b2e72b4","trusted":true},"cell_type":"markdown","source":"# Dataset Problem\nInstantiate dataset object for training procedure (e.g., train, val, and test)"},{"metadata":{"_uuid":"ed367d26-a422-48d5-bd67-5862c2dd7e9c","_cell_guid":"989a0eb1-4bb5-4b9c-a7cd-e4ddfbacd36f","trusted":true},"cell_type":"code","source":"# Instantiate data generator for training procedure\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   rotation_range = 5,\n                                   width_shift_range = 0.1,\n                                   height_shift_range = 0.05,\n                                   shear_range = 0.1,\n                                   zoom_range = 0.15,\n                                   horizontal_flip = True)\n\nval_datagen = ImageDataGenerator(rescale = 1./255)\ntest_datagen = ImageDataGenerator(rescale=1./ 255)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"664f8813-8721-4b8b-930e-2105d86444c1","_cell_guid":"2fd37682-3a06-4cdd-990b-95b8b2ab65e3","trusted":true},"cell_type":"code","source":"# Define dataset properties\ntrain_batch_size = 32\nval_batch_size = 32\nimg_width = 299\nimg_height = 299\n\n# Generate dataset for train, val and test\ntrain_gen = train_datagen.flow_from_directory(train_dir,\n                                              batch_size = train_batch_size,\n                                              class_mode = 'binary',\n                                              target_size = (img_width, img_height),\n                                              seed = seed_number)\n\nval_gen = val_datagen.flow_from_directory(val_dir,\n                                          batch_size = val_batch_size,\n                                          class_mode = 'binary',\n                                          target_size = (img_width, img_height),\n                                          seed = seed_number)\n\ntest_gen = test_datagen.flow_from_directory(test_dir,\n                                            batch_size = 1,\n                                            class_mode = 'binary',\n                                            target_size = (img_width, img_height),\n                                            seed = seed_number,\n                                            shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the dataset generator information\nprint(f'Train set batch shape\\t: {next(train_gen)[0].shape}')\nprint(f'Val set batch shape\\t: {next(val_gen)[0].shape}')\nprint(f'Test set batch shape\\t: {next(test_gen)[0].shape}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81f5cdea-2062-432a-b2ad-0267e92fb652","_cell_guid":"b60c6aad-b3cb-4d54-8299-8c9857de7d03","trusted":true},"cell_type":"markdown","source":"# Generate Model\nUsing a pre-trained Xception model, provided by tensorflow"},{"metadata":{"_uuid":"a9dc0205-4b82-4307-a7ff-73d3b5186f14","_cell_guid":"e6211808-27f0-480b-a020-bdfb760e4203","trusted":true},"cell_type":"code","source":"# Don't forget to turn on the Internet to download the respective pre-trained weights!\npretrain_net = xception.Xception(input_shape = (img_width, img_height, 3),\n                                    include_top = False,\n                                    weights = 'imagenet')\n\n# load_param_path = '../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'  # Offline alternative\n# pretrain_net.load_weights(load_param_path)  # Manually load the weights from the input directory\n\n# ------ Freezing layer(s) up to a specific layer ------\nfreeze_to = 'block4_sepconv1_act'  # use 'None' for training all the layers instead!\n\nif freeze_to:\n    for layer in pretrain_net.layers:\n        if layer.name == freeze_to:\n            break\n        else:\n            layer.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10fca13d-74df-4872-958b-328574120774","_cell_guid":"2816af8c-7902-49ce-bb2a-2d601536a5a2","trusted":true},"cell_type":"code","source":"# Adding extra layer for our problem\nx = pretrain_net.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(units=1024, activation='relu', name='extra_fc1')(x)\nx = Dropout(rate=0.3, name='extra_dropout1')(x)\nx = Dense(units=512, activation='relu', name='extra_fc2')(x)\nx = Dropout(rate=0.3, name='extra_dropout2')(x)\nx = Dense(1, activation='sigmoid', name='classifier')(x)\n\nmodel = Model(inputs=pretrain_net.input, outputs=x, name='xception_pneumonia')\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Perform Training\nDefine the training procedure"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 30  # Set the number of epochs to train\n\nmodel.compile(optimizer = Adam(lr=0.0001),\n              loss = 'binary_crossentropy',\n              metrics = ['acc'])\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch = set_length['train'] // train_batch_size,\n                    validation_data = val_gen,\n                    validation_steps = set_length['val'] // val_batch_size,\n                    epochs = num_epochs\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the train results\ntrain_accuracy = history.history['acc']\nval_accuracy = history.history['val_acc']\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\nplt.figure(figsize=(12,4))\n\n# Plotting the accuracy\nplt.subplot(1,2,1)\nplt.plot(epochs, train_accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'val'], loc='lower right')\n\n# Plotting the loss\nplt.subplot(1,2,2)\nplt.plot(epochs, train_loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['train', 'val'], loc='upper right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results evaluation\nUse this section to evaluate the model performance on the Test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test set accuracy and loss\ntest_scores = model.evaluate(test_gen)\nprint(\"Test results Accuracy: {0:.2f}% and Loss: {0:.2f}\".format(test_scores[1]*100, test_scores[0]))\n\ny_pred_value = model.predict(test_gen, steps=set_length['test'])\ny_pred = np.argmax(y_pred, axis = 1)  # Need to evaluated for binary* case. *Use threshold instead!\ny_true = test_gen.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix result\nconfusion_matrix_result = confusion_matrix(y_true, y_pred)\nplot_confusion_matrix(conf_mtx, figsize=(12,8), hide_ticks=True, alpha=0.7, cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.show()\n\n# Precision and Recall metrics\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprecision = tp / (tp+fp)\nrecall = tp / (tp+fn)\nf1_score = 2 * precision * recall / (precision+recall)\nprint(\"Precision\\t: {:.2f}%\".format(precision*100))\nprint(\"Recall\\t: {:.2f}%\".format(recall*100))\nprint(\"F1 Score\\t: {:.2f}%\".format(f1_score*100))\n\n# Classification report\nprint(classification_report(y_true, y_pred, target_names=label_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC Curve and AUC metrics\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n                                 \nplt.figure(figsize=(7, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n    \nplt.plot(fpr[0], fpr[0], 'k-', label = 'random guessing')\n\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc=\"lower right\")\n\nplt.tight_layout()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}